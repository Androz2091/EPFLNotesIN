\documentclass[a4paper]{article}

% Expanded on 2021-11-24 at 10:15:50.

\usepackage{../../style}

\title{Analyse 1}
\author{Joachim Favre}
\date{Mercredi 24 novembre 2021}

\begin{document}
\maketitle

\lecture{18}{2021-11-24}{Exponentielles, hyperboles et extrema}{
\begin{itemize}[left=0pt]
    \item Démonstration du théorème permettant de calculer la dérivée d'une fonction réciproque.
    \item Calcul de la dérivée de l'exponentielle, définition du logarithme naturel et calcul de sa dérivée. Définition de l'exponentielle et du logarithme en base quelconque, et calcul de leur dérivée.
    \item Explication de la méthode de dérivée dite de la ``dérivée logarithmique''.
    \item Définition des fonctions hyperboliques et démonstrations de leurs propriétés.
    \item Définition des points stationnaires, et explication de là où se trouvent les extrema d'une fonction.
    \item Preuve du théorème de Rolle.
\end{itemize}

}

\parag{Exemple}{
    Prenons la fonction suivante (donnée bout par bout par les étudiants de la salle):
    \[\frac{e^{x} \log{\left(\frac{1}{x^{2}} \right)} + \frac{1}{\log{\left(\sin{\left(x^{2} \right)} \right)}}}{3 x^{4} - 2 x^{3} + x + 1}\]

    Sa dérivée est alors donnée par:
    \[\frac{\left(e^{x} \log{\left(\frac{1}{x^{2}} \right)} + \frac{1}{\log{\left(\sin{\left(x^{2} \right)} \right)}}\right) \left(- 12 x^{3} + 6 x^{2} - 1\right)}{\left(3 x^{4} - 2 x^{3} + x + 1\right)^{2}} + \frac{- \frac{2 x \cos{\left(x^{2} \right)}}{\log{\left(\sin{\left(x^{2} \right)} \right)}^{2} \sin{\left(x^{2} \right)}} + e^{x} \log{\left(\frac{1}{x^{2}} \right)} - \frac{2 e^{x}}{x}}{3 x^{4} - 2 x^{3} + x + 1}\]

    Et on peut la simplifier, mais même si sympy me permet de la calculer, elle prend trois fois la taille maximale d'une ligne de ce document, et il n'y a aucun moyen de la couper proprement (et de toutes façons je parie que vous avez pas lu complètement l'équation ci-dessus).

    On voit que calculer une dérivée c'est quelque chose qui peut être fait automatiquement. On peut calculer la dérivée de n'importe quelle fonction dont on a la formule.
}

\parag{Proposition (dérivée de la fonction réciproque)}{
    Soient $I$ un intervalle ouvert, et $f : I \mapsto F$ une fonction bijective continue sur $I$ et dérivable en $x_0 \in I$, telle que $f'\left(x_0\right) \neq 0$.

    La fonction réciproque $f^{-1} : F \mapsto I$ est dérivable en $y_0 = f\left(x_0\right)$ et: 
    \[\left(f^{-1}\right)'\left(y_0\right) = \frac{1}{f'\left(x_0\right)}, \mathspace \text{où } y_0 = f\left(x_0\right) \iff x_0 = f^{-1}\left(y_0\right)\]
   
    \subparag{Note}{
        On sait que $F$ est aussi un intervalle ouvert par continuité.
    }
    

    \subparag{Preuve}{
        $f$ est continue et bijective sur $I$, donc on sait que $f^{-1}$ est continue et bijective. On peut calculer sa dérivée: 
        \[\lim_{y \to y_0} \frac{f^{-1}\left(y\right) - f^{-1}\left(y_0\right)}{y - y_0} = \lim_{y \to y_0} \frac{f^{-1}\left(y\right) - f^{-1}\left(y_0\right)}{f\left(f^{-1}\left(y\right)\right) - f\left(f^{-1}\left(y_0\right)\right)}\]
        
        Prenons le changement de variable $x = f^{-1}\left(y\right)$, donc $x_0 = f^{-1}\left(y_0\right)$. Puisque $f^{-1}\left(y\right)$ est continue en $y_0$, on sait que quand $y \to y_0$, $x \to x_0$. Notre limite est donc égale à: 
        \[\lim_{x \to x_0} \frac{x - x_0}{f\left(x\right) - f\left(x_0\right)} = \lim_{x \to x_0} \frac{1}{\frac{f\left(x\right) - f\left(x_0\right)}{x - x_0}} = \frac{1}{f'\left(x_0\right)}\]
        puisque $f'\left(x_0\right) \neq 0$.
    }
} 

\parag{Corollaire}{
    Soient $I$ et $F$, deux intervalles fermés. Si $f : I \mapsto F$ et $f^{-1} : F \mapsto I$ sont deux fonctions réciproques continues sur leurs domaines et dérivables à l'intérieur (partout, sauf aux bornes), alors pour tout $x$ à l'intérieur de $F$, tel que $f'\left(f^{-1}\left(x\right)\right) \neq 0$, on a: 
    \[\left(f^{-1}\right)'\left(x\right) = \frac{1}{f'\left(f^{-1}\left(x\right)\right)}\]

    \subparag{Remarque}{
        Il faut faire attention que la dérivée n'est \textit{pas} donnée par: 
        \[\left(f^{-1}\right)'\left(x\right) \neq \frac{1}{f'\left(x\right)}\]

        C'est une erreur commune.
    }

    \subparag{Note personnelle}{
        La ``méthode de physicien'' pour retrouver ce fait est la suivante: 
    \[f'\left(x\right) = \frac{dy}{dx} = \frac{1}{\frac{dx}{dy}} = \frac{1}{\left(f^{-1}\left(y\right)\right)'}\]
    }
}

\parag{Exemple}{
    Prenons la fonction $\arccos\left(x\right) : \left[-1, 1\right] \mapsto \left[0, \pi\right]$ et $\cos\left(x\right) : \left[0, \pi\right] \mapsto \left[-1, 1\right]$. On a bien:
    \[y = \arccos\left(x\right) \iff x = \cos\left(y\right)\]

    Donc: 
    \[\left(\arccos\left(x\right)\right)' = \frac{1}{\cos'\left(\arccos\left(x\right)\right)} = \frac{1}{-\sin\left(\arccos\left(x\right)\right)} = - \frac{1}{\sqrt{1 - x^2}}\]

    En effet, on sait que $\sin\left(y\right) = \pm\sqrt{1 - \cos^2\left(y\right)}$. Cependant, puisque $0 \leq \arccos\left(x\right) \leq \pi$, on a que $\sin\left(\arccos\left(x\right)\right) > 0$. Ainsi, on on choisit la version positive et on trouve notre résultat ci-dessus.
}


\parag{Dérivée de l'exponentielle}{
    On veut calculer la dérivée de $f\left(x\right) = e^x$. On a: 
    \[f'\left(x_0\right) = \lim_{x \to x_0} \frac{e^x - e^{x_0}}{x - x_0} = \lim_{x \to x_0} e^{x_0} \frac{e^{x - x_0} - 1}{x - x_0}\]

    Prenons le changement de variable $t = x - x_0$: 
    \[f'\left(x_0\right) = e^{x_0}\lim_{t \to 0} \frac{e^t - 1}{t} = e^{x_0}, \mathspace \forall x_0 \in \mathbb{R}\]
    
    On a donc trouvé que: 
    \[\left(e^x\right)' = e^x, \mathspace \forall x \in \mathbb{R}\]
    
    Puisque $e^x$ est dérivable pour tout $x \in \mathbb{R}$, elle est continue $\forall x \in \mathbb{R}$. Ainsi, puisqu'on sait qu'elle est continue et strictement monotone, alors $f\left(\text{intervalle ouvert}\right) = \text{intervalle ouvert}$. Ainsi, en le mettant en commun avec ses limites, on trouve que $f\left(\mathbb{R}\right) = \left]0, +\infty\right[ = \mathbb{R}^*_+$. On en déduit donc que $f$ est surjective.

    Puisque $f\left(x\right) = e^x$ est continue, bijective et monotone, alors on sait qu'il existe une fonction inverse qui est continue, bijective et monotone:
    \[\begin{split}
        f^{-1}: \mathbb{R}^*_+ &\longmapsto \mathbb{R} \\
        x &\longmapsto \log\left(x\right)
    \end{split}\]
}

\parag{Dérivée du logarithme}{
    Soit $f^{-1}\left(x\right) = \log\left(x\right)$, $f\left(y\right) = e^y$, avec $x > 0$. On veut calculer la dérivée du logarithme: 
    \[\left(\log\left(x\right)\right)' = \frac{1}{\left(e^y\right)'} \eval_{y = \log\left(x\right)}^{} = \frac{1}{e^y} \eval_{y = \log\left(x\right)}^{} = \frac{1}{e^{\log\left(x\right)}} = \frac{1}{x}, \mathspace \forall x > 0\]
    
    Ainsi, on a trouvé que: 
    \[\left(\log\left(x\right)\right)' = \frac{1}{x}, \mathspace \forall x > 0\]
}

\parag{Remarque}{
    On peut définir la fonction suivante: 
    \[a^x \over{=}{déf} e^{x \log\left(a\right)}, \mathspace \forall x \in \mathbb{R}, a > 0, a \neq 1\]
    
    On peut aussi trouver la fonction réciproque: 
    \[y = e^{x \log\left(a\right)} \iff \log\left(y\right) = x \log\left(a\right) \iff x = \frac{\log\left(y\right)}{\log\left(a\right)}\]
    
    On sait que $\log\left(a\right) \neq 0$ puisque $a \neq 1$. On définit donc: 
    \[\log_a\left(y\right) \over{=}{déf} \frac{\log\left(y\right)}{\log\left(a\right)}, \mathspace \forall y \in \mathbb{R}^*_+, a > 0, a \neq 1\]


    Calculons leur dérivée: 
    \[\left(a^x\right)' = \left(e^{x \log\left(a\right)}\right)' = \log\left(a\right) e^{x \log\left(a\right)} = a^x\log\left(a\right)\]
    \[\left(\log\left(a\right)\right)' = \left(\frac{\log\left(x\right)}{\log\left(a\right)}\right)' = \frac{1}{x\log\left(a\right)}\]
}

\parag{Dérivée logarithmique}{
    Soit $f\left(x\right) = f_1\left(x\right)^{f_2\left(x\right)}$. Nous voulons calculer sa dérivée. Pour commencer, utilisons la définition de l'exponentielle en base $a$: 
    \[f\left(x\right) = f_1\left(x\right)^{f_2\left(x\right)} = e^{f_2\left(x\right) \log\left(f_1\left(x\right)\right)}\]
    
    On peut maintenant calculer sa dérivée: 
    \begin{multiequality}
        f'\left(x\right) =\ & \left(e^{f_2\left(x\right)\log\left(f_1\left(x\right)\right)}\right)' \\
        =\ & e^{f_2\left(x\right)\log\left(f_1\left(x\right)\right)} \left(f_2'\left(x\right)\log\left(f_1\left(x\right)\right) + f_2\left(x\right) \frac{f_1'\left(x\right)}{f_1\left(x\right)}\right)  \\
        =\ & f_1\left(x\right)^{f_2\left(x\right)}\log\left(f_1\left(x\right)^{f_2\left(x\right)}\right)  \\
        =\ & f\left(x\right) \left(\log\left(f\left(x\right)\right)\right)' 
    \end{multiequality}

        De manière générale, on trouve donc que: 
        \[\left(f\left(x\right)\right)' = f\left(x\right)\left(\log\left(f\left(x\right)\right)\right)'\]
        si le logarithme est bien défini.

        Ce résultat est indispensable pour calculer les fonctions qui sous la forme $f_1\left(x\right)^{f_2\left(x\right)}$, et est très pratique si nous avons un très gros produit.
}

\parag{Exemple}{
    Disons que nous voulons calculer la dérivée de la fonction suivante: 
    \[f\left(x\right) = \left(x^2 + 1\right)^{\sin\left(x\right)}\]
    
    On a que $x^2 + 1 > 0$ pour tout $x$, donc $\log\left(x^2 + 1\right)$ est bien défini pour tout $x$. Ainsi, la dérivée est donnée par: 
    \[f'\left(x\right) = \left(x^2 + 1\right)^{\sin\left(x\right)} \left(\cos\left(x\right) \log\left(x^2 + 1\right) + \sin\left(x\right) \cdot \frac{2x}{x^2 + 1}\right)\]
    puisque $\log\left(x^2 + 1\right)^{\sin\left(x\right)} = \sin\left(x\right)\log\left(x^2 + 1\right)$.
}

\subsection{Fonctions hyperboliques}
\parag{Définition}{
    On définit le sinus hyperbolique:
    \[\sh\left(x\right) = \sinh\left(x\right) \over{=}{déf} \frac{e^{x} - e^{-x}}{2}\]
    
    C'est une fonction impaire, définie pour $\forall x \in \mathbb{R}$. On peut aussi définir le cosinus hyperbolique: 
    \[\ch\left(x\right) = \cosh\left(x\right) \over{=}{déf} \frac{e^x + e^{-x}}{2}\]
    
    \imagehere{graphiqueSinhCosh.png}

    \subparag{Rappel}{
        On avait trouvé que: 
        \[\sin\left(x\right) = \frac{e^{ix} - e^{-ix}}{2i}, \mathspace \cos\left(x\right) = \frac{e^{ix} + e^{-ix}}{2} \]
    }

    \subparag{Note personnelle}{
        Si on prend les formules ci-dessus comme définition du sinus et du cosinus complexe, alors on trouve: 
        \[\sin\left(ix\right) = \frac{e^{-x} - e^{x}}{2} \cdot \left(-i\right) = i \frac{e^{x} - e^{-x}}{2} = i\sinh\left(x\right)\]
        \[\cos\left(ix\right) = \frac{e^{-x} + e^{x}}{2} = \cosh\left(x\right)\]
        
        De plus, on remarque qu'on peut séparer n'importe quelle fonction comme la somme d'une fonction impaire et d'une fonction paire, de manière unique. $\cosh\left(x\right)$ et $\sinh\left(x\right)$ sont ces fonctions pour $\exp\left(x\right)$: 
        \[\exp\left(x\right) = \cosh\left(x\right) + \sinh\left(x\right)\]

        Et: 
        \[\sinh\left(-x\right) = -\sinh\left(x\right), \mathspace \cosh\left(-x\right) = -\cosh\left(x\right)\]
        
        Finalement, $\left<\cosh\left(t\right), \sinh\left(t\right)\right>$ est la paramétrisation de la branche positive de l'hyperbole ($y^2 = x^2 - 1$), là où $\left<\cos\left(t\right), \sin\left(t\right)\right>$ est la paramétrisation du cercle ($y^2 = 1 - x^2$).
    }
    
}

\parag{Dérivée}{
    On remarque que leurs dérivées sont symmétriques: 
    \[\left(\sinh\left(x\right)\right)' = \cosh\left(x\right), \mathspace \left(\cosh\left(x\right)\right)' = \sinh\left(x\right)\]
    
    On remarque que, contrairement au sinus et au cosinus classiques, il n'y a pas de moins. La dérivée du sinus et du cosinus sont ``périodiques'' toutes les 4 dérivées, celles des sinus et cosinus hyperboliques sont ``périodiques'' toutes les 2 dérivées.
}

\parag{Propriété}{
    On remarque que ces fonctions ont la propriété suivante: 
    \[\cosh^2\left(x\right) - \sinh^2\left(x\right) = \frac{e^{2x} + 2 + e^{-2x} - e^{2x} + 2 - e^{-2x}}{4} = \frac{4}{4} = 1\]
    
}


\parag{Tangente et cotangente hyperbolique}{
    On définit: 
    \[\badth\left(x\right) = \tanh\left(x\right) \over{=}{déf} \frac{\sinh\left(x\right)}{\cosh\left(x\right)} = \frac{e^{x} - e^{-x}}{e^x + e^{-x}}, \mathspace \forall x \in \mathbb{R}\]
    
    On remarque que $-1 < \tanh\left(x\right) < 1$ pour tout $x$. De plus, on définit: 
    \[\coth \over{=}{déf} \frac{\cosh\left(x\right)}{\sinh\left(x\right)} = \frac{e^x + e^{-x}}{e^{x} - e^{-x}}, \mathspace \forall x \in \mathbb{R}^*\]
}

\parag{Fonctions réciproques}{
    On parle de ``l'argument du sinus hyperbolique'', donc on note la fonction inverse $\Argsh = \arcsinh : \mathbb{R} \mapsto \mathbb{R}$. On a: 
    \[y = \sinh\left(x\right) \iff x = \arcsinh\left(y\right), \mathspace \forall x, y \in \mathbb{R}\]

    On peut calculer la dérivée de cette fonction: 
    \[\left(\arcsinh\left(y\right)\right)' = \frac{1}{\sinh'\left(\arcsinh\left(y\right)\right)} = \frac{1}{\cosh\left(\arcsinh\left(y\right)\right)}\]
    
    On a $\cosh\left(x\right) = \pm \sqrt{1 + \sinh^2\left(x\right)}$. Mais, puisque $\cosh\left(x\right) > 0$ pour tout $x$ on prend la version positive. Donc:
    \[\left(\arcsinh\left(y\right)\right)' = \frac{1}{\sqrt{1 + \sinh^2\left(\arcsinh\left(y\right)\right)}} = \frac{1}{\sqrt{1 + y^2}}, \mathspace \forall y \in \mathbb{R}\]

    On peut aussi trouver des fonctions réciproques pour les autres fonctions hyperboliques.
}

\subsection{Dérivées multiples}
\parag{Définition}{
    On définit la \important{dérivée d'ordre 2} comme: 
    \[f''\left(x\right) \over{=}{déf} \left(f'\left(x\right)\right)'\]
    
    De la même manière, on définit la \important{dérivée d'ordre $n$} par: 
    \[f^{\left(n\right)}\left(x\right) \over{=}{déf} \left(f^{\left(n-1\right)}\left(x\right)\right)\]
    
    Il est important de faire la différence avec les puissances. Pour des dérivées d'ordre $n$, on met des parenthèses, pas pour les puissances.
}

\parag{Exemple}{
    Soit $f\left(x\right) = x^n$, avec $n \in\mathbb{N}^*$. On sait que $f'\left(x\right) = nx^{n-1}$. En calculant la dérivée seconde, on a $f''\left(x\right) = n\left(n-1\right)x^{n-2}$. On peut continuer ainsi de suite jusqu'à $f^{\left(n\right)} = n!$. Ensuite, on trouve que $f^{\left(n+1\right)} = 0$.

    On peut démontrer ceci par récurrence.
}

\parag{Définition}{
   $f : E \mapsto F$ est \important{$n$ fois dérivable} si elle admet une dérivée d'ordre $n$.
}

\parag{Définition de classe}{
    $f : E \mapsto F$ est \important{de classe $C^n\left(E\right)$} si elle admet une dérivée d'ordre $n$ qui est continue sur $E$. On dit qu'elle est ``$n$ fois continûment dérivable''.
}

\parag{Exemple}{
    $f\left(x\right) = \sin\left(x\right)$ est indéfiniment continûment dérivable sur $\mathbb{R}$. On dit donc que $\sin\left(x\right)$ est de classe $C^{\infty}\left(\mathbb{R}\right)$.

    Les polynômes appartiennent aussi à $C^{\infty}\left(\mathbb{R}\right)$ (on peut utiliser le symbole $\in$).
}

\subsection{Théorème des accroissement finis}
\parag{Proposition}{
    Si $f : E \mapsto F$ est une fonction dérivable en $x_0 \in E$ telle que $f$ admet un extremum local en $x_0$, alors $f'\left(x_0\right) = 0$.

    \subparag{Preuve}{
        Soit $f\left(x_0\right)$ un maximum local de $f\left(x\right)$. Alors, $f\left(x_0\right) \geq f\left(x\right)$ pour tout $x$ dans un voisinage de $x_0$.

        Puisque la fonction est dérivable en $x_0$, les dérivées sur le côté sont égales: 
        \[f'_d\left(x\right) = \lim_{x \to x_0^+} \frac{\overbrace{f\left(x\right) - f\left(x_0\right)}^{\leq 0}}{\underbrace{x - x_0}_{> 0}} \leq 0 \]
        \[f'_g\left(x\right) = \lim_{x \to x_0^-} \frac{\overbrace{f\left(x\right) - f\left(x_0\right)}^{\leq 0}}{\underbrace{x - x_0}_{< 0}} \geq 0 \]

        Ainsi, puisque $f'_d\left(x\right) = f'_g\left(x\right)$, elles sont forcément égales à 0.

        La preuve est similaire si $f\left(x_0\right)$ est un minimum local de $f\left(x\right)$.
    }

    \subparag{Réciproque}{
        La réciproque est fausse. En effet, prenons par exemple $f\left(x\right) = x^3$ en $x_0 = 0$. On a bien que  
        \[f'\left(0\right) = 3x^2 \eval_{x=0}^{} = 0\]
        
        Cependant, $f\left(x\right)$ n'a pas d'extremum local en $x = 0$.
    }
}

\parag{Définition des points stationnaires}{
    Si $f : E \mapsto F$ est dérivable en $x_0$ et $f'\left(x_0\right) = 0$, on dit que $x_0$ est un \important{point stationnaire} de $f$.
}

\parag{Observation}{
    On remarque que les points d'extrema d'une fonction $f : \left[a, b\right] \mapsto \mathbb{R}$ sont parmi les suivants:
    \begin{enumerate}
        \item Les points stationnaires : $f'\left(x_0\right) = 0$.
        \item Les points $x \in \left]a, b\right[$ où $f'\left(x\right)$ n'existe pas.
        \item Les bornes $x = a$ et $x = b$.
    \end{enumerate}
}

\parag{Théorème de Rolle}{
    Soient $a < b \in \mathbb{R}$ et $f : \left[a, b\right] \mapsto F$ telle que:
    \begin{enumerate}
        \item $f : \left[a, b\right] \mapsto F$ est continue
        \item $f$ est dérivable sur $\left]a, b\right[ $
        \item $f\left(a\right) = f\left(b\right)$
    \end{enumerate}
    
    Alors, il existe au moins un point $c \in \left]a, b\right[$ tel que $f'\left(c\right) = 0$.

    \subparag{Preuve}{
        Si $f : \left[a, b\right] \mapsto F$ est constante, on a: 
        \[f'\left(x_0\right) = \lim_{x \to x_0} \frac{f\left(x\right) - f\left(x_0\right)}{x - x_0} = \lim_{x \to x_0} \frac{c - c}{x - x_0} = 0, \mathspace \forall x_0 \in \left]a, b\right[ \]
        
        \vspace{1em}

        Si $f : \left[a, b\right] \mapsto F$ n'est pas constante, on sait qu'il existe $z_1 \neq z_2 \in \left[a, b\right]$ où: 
        \[f\left(z_1\right) = \min_{\left[a, b\right]}f\left(x\right), \mathspace f\left(z_2\right) = \max_{\left[a,b\right]}f\left(x\right), \mathspace f\left(z_1\right) \neq f\left(z_2\right)\]
        
        En effet, si $f\left(z_1\right) = f\left(z_2\right)$, la fonction serait constante (c'est la seule possibilité pour que le maximum soit égal au minimum).

        Cependant, puisque $f\left(a\right) = f\left(b\right)$, on sait qu'au moins un entre $z_1$ et $z_2$ est dans $\left]a, b\right[ $. Prenons sans perte de généralité (SPDG) que $z_1 \in \left]a,b\right[ $. On sait que $f'\left(z_1\right) = 0$ puisque $z_1$ est un extremum local et $f$ est dérivable sur $\left]a,b\right[ $. Ainsi, en posant $c = z_1$, on a trouvé: 
        \[f'\left(c\right) = 0\]
        
        \qed
    }
    

    \subparag{Application physique}{
        Il existe toujours une tangente horizontale pour une corde suspendue entre deux points de même hauteur.

        \imagehere[0.5]{CordeASauterHeHe.png}
    }
    
}






\end{document}
