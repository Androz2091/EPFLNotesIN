\documentclass[a4paper]{article}

% Expanded on 2022-05-20 at 08:58:42.

\usepackage{../../style}

\title{AICC 2}
\author{Joachim Favre}
\date{Jeudi 19 mai 2022}

\begin{document}
\maketitle

\lecture{24}{2022-05-19}{Hamming code}{
    \begin{itemize}[left=0pt]
        \item Definition of parity-check matrix.
        \item Proof of a theorem giving the parity-check matrix for free out of a systematic generator matrix.
        \item Definition of Hamming code, and proof they have $d_{min} = 3$.
    \end{itemize}
}

\parag{Example 3}{
    Let us consider the following generator matrix in $\mathbb{F}_5^5$: 
    \[G = \begin{pmatrix} 0 & 1 & 2 & 3 & 4 \\ 4 & 3 & 2 & 1 & 0 \\ 1 & 1 & 0 & 1 & 1 \end{pmatrix} \]
    
    Since the first column has a zero in the first line, the second line has a zero in the last column, and the third line has a zero in the third column, the lines are linearly independent and thus it has the maximum rank, $\rank\left(G\right) = 3$. Let's do Gaussian elimination over this matrix. First, let's swap the first and the third row:
    \[G' = \begin{pmatrix} 1 & 1 & 0 & 1 & 1 \\ 4 & 3 & 2 & 1 & 0 \\ 0 & 1 & 2 & 3 & 4 \end{pmatrix} \]

    Then, let's subtract four times the first row from the second one: 
    \[G'' = \begin{pmatrix} 1 & 1 & 0 & 1 & 1 \\ 0 & 1 & 2 & 3 & 4 \\ 0 & 4 & 2 & 2 & 1 \end{pmatrix} \]
    
    After that, let's subtract four time the second column from the last one: 
    \[G''' = \begin{pmatrix} 1 & 1 & 0 & 1 & 1 \\ 0 & 1 & 2 & 3 & 4 \\ 0 & 0 & 4 & 0 & 0 \end{pmatrix} \]
    
    As the next step, let's subtract the second line from the first line, and multiply the last line by $4^{-1} = 4$: 
    \[G'''' = \begin{pmatrix} 1 & 0 & 3 & 3 & 2 \\ 0 & 1 & 2 & 3 & 4 \\ 0 & 0 & 1 & 0 & 0 \end{pmatrix} \]
    
    Finally, subtracting multiples of the last line from the first and the second line: 
    \[G_{sys} = \begin{pmatrix} 1 & 0 & 0 & 3 & 2 \\ 0 & 1 & 0 & 3 & 4 \\ 0 & 0 & 1 & 0 & 0 \end{pmatrix} \]
}

\parag{Recall}{
    Recall that, to describe a code, there are two ways. Either we can use the basis (and thus a generator matrix), which is convenient for encoding, or we can use $\left(n-k\right)$ linear homogeneous equations (like representing some kind of orthogonal space), which is convenient for decoding: we can just check if $\bvec{y}$ satisfies all $\left(n-k\right)$ equations to know if it is a codeword. 
}

\parag{Example}{
    Let $\mathcal{C} \subseteq \mathbb{F}_3^4$ be the solutions to: 
    \[\begin{systemofequations} y_1 + 2y_2 + 2y_3 + y_4 = 0 \\ 2y_i + 2y_2 + y_3 + y_4 = 0\end{systemofequations}\]
    
    We can represent this as a matrix:
    \[\begin{pmatrix} y_1 & y_2 & y_3 & y_4 \end{pmatrix} \begin{pmatrix} 1 & 2 & 2 &  1 \\ 2 & 2 & 1 & 1 \end{pmatrix}^T = \bvec{0} \implies \bvec{y} H^T = \bvec{0}\]

    The subspace is 2 since the two rows of our matrix are linearly independent, and thus $n - k = 2 \implies k = 2$. We also see that $\bvec{y} \in \mathbb{F}_3^{4}$ is in $\mathcal{C}$ if and only if $\bvec{y} H^T = \bvec{0}$.
}

\parag{Definition: Parity-check matrix}{
    A \important{parity-check matrix} $H$ for a linear $\left(n, k\right)$ block code $\mathcal{C}$ is an $\left(n-k\right)\times n$ matrix that contains the coefficients of the $n-k$ linear homogenous equations, the solutions to which construct $\mathcal{C}$.

    This tells us $H \in \mathbb{F}^{\left(n-k\right) \times n}$ is such that:
    \[\bvec{y} H^T = \bvec{0} \iff \bvec{y} \in \mathcal{C}\]
}

\parag{Lemma}{
    Let $G$ and $H$ be full rank matrices (their rank is the highest it can be) and the right dimension.

    $\left(G, H\right)$ are generator/parity-check matrices if and only if: 
    \[GH^T = 0\]
}


\parag{Theorem: Systematic code}{
    Let's say we have the following systematic generator matrix: 
    \[G = \begin{pmatrix}  &  &  &  &  &  \\  & I_k &  &  & P &  \\  &  &  &  &  &  \end{pmatrix} \]
    
    Then, the parity-check matrix is given by: 
    \[H = \begin{pmatrix}  &  &  &  &  &  \\  & -P^T &  &  & I_{n-k} &  \\  &  &  &  &  &  \end{pmatrix} \]
    
    \subparag{Proof}{
        Let's first check the matrix dimensions. We know $P \in \mathbb{F}^{k \times \left(n-k\right)}$, and thus $P^T \in \mathbb{F}^{\left(n-k\right) \times k}$. This tells us that $H$ has $n-k$ rows and $n$ columns, as expected. Also, we can see that the $n-k$ rows of $H$ are linearly independent, thus both matrices are full rank.

        Finally, we need to check if $G H^T = 0$: 
        \[G H^T = \begin{pmatrix}  &  &  &  &  &  \\  & I_k &  &  & P &  \\  &  &  &  &  &  \end{pmatrix} \begin{pmatrix}  &  &  \\  & -P &  \\  &  &  \\  &  &  \\  & I_{n-k} &  \\  &  &  \end{pmatrix} = -P + P = 0\]

        \qed
    }
    
}

\parag{Example 1}{
    Let us have a code $\mathcal{C} \subseteq \mathbb{F}_5^5$ where $k = 3$ and its generator matrix is given by: 
    \[G = \begin{pmatrix} 1 & 0 & 0 & 3 & 2 \\ 0 & 1 & 0 & 3 & 4 \\ 0 & 0 & 1 & 0 & 0 \end{pmatrix} \]
    
    We can observe that this is a systematic generator matrix, thus we can compute its parity-check matrix for free: 
    \[H = \begin{pmatrix} -3 & -3 & 0 & 1 & 0 \\ -2 & -4 & 0 & 0 & 1 \end{pmatrix} = \begin{pmatrix} 2 & 2 & 0 & 1 & 0 \\ 3 & 1 & 0 & 0 & 1 \end{pmatrix} \]
    
    We can see that the dimensions match. Let's do a quick check: 
    \[G H^T = \begin{pmatrix} 1 & 0 & 0 & 3 & 2 \\ 0 & 1 & 0 & 3 & 4 \\ 0 & 0 & 1 & 0 & 0 \end{pmatrix} \begin{pmatrix} 2 & 3 \\ 2 & 1 \\ 0 & 0 \\ 1 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 0 \\ 0 & 0 \end{pmatrix} = 0\]
}

\parag{Example 2}{
    Let's consider the code $\mathcal{C} \subseteq \mathbb{F}_q^n$, where: 
    \[\mathcal{C} = \left\{\left(c_1, \ldots, c_n\right) \in \mathbb{F}_q^n : \sum_{i=1}^{n} c_i = 0\right\}\]
    
    The parity matrix for this code is given by: 
    \[H = \begin{pmatrix} 1 & \cdots & 1 \end{pmatrix} \]
    
    We notice that $\rank\left(H\right) = 1$. Also, this is a systematic code since we have the identity matrix ($I_1 = 1$) in the last $n-k = 1$ columns. Thus, we can find the generator matrix: 
    \[G = \begin{pmatrix} 1 & 0 & \cdots & 0 & 1 \\ 0 & 1 & \cdots & 0 & 1 \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & \cdots & 1 & 1 \end{pmatrix} \]
}

\parag{Definition: Syndrome}{
    Let $\mathcal{C} \subseteq \mathbb{F}^n$  be an $\left(n, k\right)$ linear block code with parity check matrix $H$.

    The vector $\bvec{s} = \bvec{y} H^T \in \mathbb{F}^{n-k}$ is the \important{syndrome} of $\bvec{y}$.

    \subparag{Observation 1}{
        We notice that, by definition of the parity-check matrix: 
        \[\bvec{s} = \bvec{0} \iff \bvec{y} \in \mathcal{C}\]
    }

    \subparag{Observation 2}{
        Let's say we are sending a codeword $\bvec{x} \in \mathbb{F}^n$ through an error channel, and we get $\bvec{y} = \bvec{x} + \bvec{e}$, where $\bvec{e} = \bvec{y} - \bvec{x} \in \mathbb{F}^n$ is the error pattern. We get that the syndrome of $\bvec{y}$ is: 
        \[\bvec{s} = \bvec{y} H^T = \bvec{x} H^T + \bvec{e} H^T = \bvec{e} H^T\]

        Thus, if there is only one error, meaning $\bvec{e} = \bvec{e_i} = \left(0, \ldots, 0, 1, 0, \ldots, 0\right)$ which has 0s everywhere except in the $i$\Th position, where it has 1, then $\bvec{s}$ is the $i$\Th column of $H^T$. This is a very interesting property.
    }
    
}

\parag{Definition: Hamming code}{
    Let $n = 2^m - 1 \in \left\{1, 3, 7, 15, 31, \ldots\right\}$ and $k = n - m$ for some $m \in \mathbb{Z}_+$. A $\left(n, k\right)$ linear code $\mathcal{C} \subseteq \mathbb{F}_2^n$ is named a \important{Hamming code} if the binary representation of every number between $1$ and $2^m$ are represented in the columns exactly once (their order does not matter).

    \subparag{Remark}{
        This must not be mistaken with Huffman codes we saw earlier, which are completely different.
    }
}

\parag{Example}{
    Let's consider the $\left(7, 4\right)$ Hamming code. We write all possible binary numbers in the columns, except for the all zero one (the order of the column does not matter): 
    \[H = \begin{pmatrix} 1 & 0 & 1 & 0 & 1 & 0 & 1 \\ 0 & 1 & 1 & 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 1 & 1 & 1 & 1 \end{pmatrix} \]
    
    This explains why $n = 2^m - 1$: we have $2^m$ possible binary number, $2^m - 1$ if we exclude the zero.

    Let's now say we want to consider the generator matrix of $\left(7, 4\right)$ hamming. First, we need to consider the Hamming* code, which has the systematic form: 
    \[\widetilde{H} =  \begin{pmatrix} 1 & 1 & 0 & 1 & 1 & 0 & 0 \\ 1 & 0 & 1 & 1 & 0 & 1 & 0 \\ 0 & 1 & 1 & 1 & 0 & 0 & 1 \end{pmatrix} \]

    Thus, the generator matrix is: 
    \[\widetilde{G} = \begin{pmatrix} 1 & 0 & 0 & 0 & 1 & 1 & 0 \\ 0 & 1 & 0 & 0 & 1 & 0 & 1 \\ 0 & 0 & 1 & 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 1 & 1 & 1 & 1 \end{pmatrix} \]
    
    We could finally unswap the columns.
}

\parag{Minimum distance}{
    Let $m = 4$, so $n = 2^4 - 1 = 15$. This gives us:
    \setcounter{MaxMatrixCols}{20}  % https://tex.stackexchange.com/a/95163
    \[H = \begin{pmatrix} 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 \\ 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \end{pmatrix} \]
    \setcounter{MaxMatrixCols}{10}
    
    We thus get that:
    \[\mathcal{C} = \left\{\bvec{c} \in \mathbb{F}_2^n : \bvec{c} H^T = \bvec{0}\right\}\]

    Now we want to know the dimension of $\mathcal{C}$. Since we are constraining 4 dimensions with our parity check, we get $\dim\left(\mathcal{C}\right) = 15 - 4 = 11$.

    Now, let's determine $d_{min}\left(\mathcal{C}\right)$. Let $\bvec{c} \in \mathcal{C}$ be the input to an error channel. Then, the output of the error channel is $\bvec{y} = \bvec{c} + \bvec{e}$, where $\bvec{e}$ is an error pattern. As we discussed earlier the syndrome of $\bvec{y}$ is given by:
    \[\bvec{s} = \bvec{y} H^T = \bvec{e} H^T\]

    Now, let's suppose that for some reason there was only one error, thus $\bvec{e} = \bvec{e_i}$: 
    \[\bvec{s} = \bvec{y} H^T = \bvec{e_i} H^T = i^{\text{th}} \text{ column of $H$} = \text{binary expansion of $i$}\]
    
    However, knowing the binary expansion of $i$ is equivalent to knowing where the error was made. Thus, we can correct every single error. This implies that $d_{min}\left(\mathcal{C}\right) \geq 3$. Let's prove that we cannot do better than 3. 

    We notice there is no codeword of weight 1, since it would mean picking up the $i$\Th column. Generally, if $\bvec{e}$ has a 1 in the $i$\Th column the $j$\Th column and the $\ell $\Th column, we get: 
    \[\bvec{e}H^T = h_i + h_j + h_\ell \]
    
    However, we can pick $i = 1$, $j = 2$, $\ell = 3$, adding up the first three columns, we do get the zero vector.

    Using the exact same argument, we can show that any Hamming code has $d_{min} = 3$.
}

\parag{Singleton bound}{
    For Hamming codes, we have: 
    \[3 = d_{min} \leq n -k + 1 = 2^m -1 - \left(2^m - 1 - m\right) + 1 = m + 1\]
    
    Thus, they are not MDS codes.
}

\parag{Theorem: Minimum distance via parity check matrix}{
    Let $\mathcal{C} \subseteq \mathbb{F}_q^n$ be a linear $\left(n, k\right)$ code and $H$ be a parity check matrix for $\mathcal{C}$. 

    Then, $d_{min}\left(\mathcal{C}\right)$ is the smallest number of linearly dependent columns of $H$.

    \subparag{Remarks}{
        We could have used this theorem for showing that Hamming codes have $d_{min} = 3$; and the proof is similar.

        Also, this theorem still has a cost, since we have to look for every combination of linearly dependant vectors.
    }
    

    \subparag{Proof}{
        We know that: 
        \begin{multiequality}
        \mathcal{C} =\ & \left\{\bvec{c} : \bvec{c} H^T = \bvec{0}\right\} \\
        =\ & \left\{\bvec{c} : \left(c_1, \ldots, c_n\right) \begin{pmatrix}  & \bvec{h_1} &  \\  & \vdots &  \\  & \bvec{h_n} &  \end{pmatrix} = 0\right\} \\
        =\ & \left\{\bvec{c} : c_1 \bvec{h_1} + \ldots + c_n \bvec{h_n} = 0\right\} 
        \end{multiequality}
    
        We use the last form of this set to prove the theorem.

        Let $\bvec{c}\in \mathcal{C}$ such that $w\left(\bvec{c}\right) = d_{min}\left(\mathcal{C}\right)$. Since it is a codeword, we know $\bvec{c} H^T = \bvec{0}$. Also, we know that $\bvec{c}$ has $w\left(\bvec{c}\right)$ components which are non-zero, and thus, looking at $\mathcal{C}$, we see that there exists $w\left(\bvec{c}\right)$ columns in $H$ that are linearly dependent.

        Conversely, let $\bvec{y} \in \mathbb{F}^n$ be a generic vector such that $0 < w\left(\bvec{y}\right) < d_{min}\left(\mathcal{C}\right)$. It cannot be in the code since we know the minimum distance is equal to the minimum Hamming weight. Again, looking at $\mathcal{C}$, we see that any $w\left(\bvec{y}\right)$ columns of $H$ are linearly independent.

        \qed

    }
    
}




\end{document}
