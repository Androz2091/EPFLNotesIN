% !TeX program = lualatex

\documentclass[a4paper]{article}

% Expanded on 2022-04-11 at 17:22:48.

\usepackage{../../style}

\title{Analyse 2}
\author{Joachim Favre}
\date{Mercredi 13 avril 2022}

\begin{document}
\maketitle

\lecture{16}{2022-04-13}{Retour aux intégrales}{
\begin{itemize}[left=0pt]
    \item Explication de l'application du théorème du Jacobien pour les fonctions composées aux changements de variables.
    \item Explication et preuve de comment calculer la dérivée partielle d'une intégrale selon une variable d'une fonction de plusieurs variables.
\end{itemize}
}

\begin{parag}{Exemple 3}
    Prenons les fonctions suivantes:
    \[\bvec{g}\left(x\right) = \begin{pmatrix} x^3 \\ \frac{1}{x} \end{pmatrix}, \mathspace f\left(u, v\right) = uv^2\]

    \begin{subparag}{Composée 1}
        Nous pouvons calculer leur composée dans un sens:
        \[f \circ \bvec{g}\left(x\right) = f\left(g_1\left(x\right), g_2\left(x\right)\right) = f\left(x^3, \frac{1}{x}\right) = x^3 \frac{1}{x^2} = x\]

        Ainsi, nous savons que notre but est de trouver $J_{f \circ \bvec{g}}\left(x\right) = \left(f \circ \bvec{g}\right)'\left(x\right) = 1$. Calculons les matrices Jacobiennes de nos deux fonctions:
        \[J_{\bvec{g}}\left(x\right) = \begin{pmatrix} \frac{\partial g_1}{\partial x} \\ \frac{\partial g_2}{\partial x} \end{pmatrix} = \begin{pmatrix} 3x^2 \\ -\frac{1}{x^2} \end{pmatrix} \]
        \begin{multiequality}
        J_{f}\left(\bvec{g}\left(x\right)\right) =\ & \nabla f\left(u, v\right) \eval_{\left(g_1\left(x\right), g_2\left(x\right)\right)}^{} = \left(v^2, 2uv\right) \eval_{\left(g_1\left(x\right), g_2\left(x\right)\right)}^{}  \\
        =\ & \left(\frac{1}{x^2}, 2x^3 \cdot \frac{1}{x}\right) = \left(\frac{1}{x^2}, 2x^2\right) 
        \end{multiequality}

        Ainsi, nous obtenons bien que:
        \[J_{f \circ \bvec{g}}\left(x\right) = J_f\left(\bvec{g}\left(x\right)\right) J_{\bvec{g}}\left(x\right) = \begin{pmatrix} \frac{1}{x^2} & 2x^2 \end{pmatrix} \begin{pmatrix} 3x^2 \\ -\frac{1}{x^2} \end{pmatrix} = 3 - 2 = 1\]
    \end{subparag}


    \begin{subparag}{Composée 2}
        Nous pouvons aussi considérer la fonction composée dans l'autre sens: $\bvec{g} \circ f : \mathbb{R}_+^2  \mapsto \mathbb{R}_+^2$:
        \[\bvec{g}\circ f\left(x, y\right) = \bvec{g}\left(xy^2\right) = \begin{pmatrix} x^3 y^6 \\ \frac{1}{x y^2} \end{pmatrix} \]

        Nous pouvons calculer la matrice Jacobienne, puisque la fonction est dérivable sur $\mathbb{R}_+^2$:
        \[J_{\bvec{g} \circ f} = \begin{pmatrix} 3x^2 y^6 & 6x^3 y^5 \\ - \frac{1}{x^2 y^2} & -\frac{2}{xy^3} \end{pmatrix} \]

        De plus, calculons les matrices Jacobiennes de nos deux fonctions:
        \[J_f\left(x, y\right) = \nabla f\left(x, y\right) = \left(y^2, 2xy\right)\]
        \[J_{\bvec{g}}\left(u\right) = \begin{pmatrix} 3u^2 \\ -\frac{1}{u^2} \end{pmatrix} \implies J_{\bvec{g}}\left(f\left(x, y\right)\right) = \begin{pmatrix} 3x^2 y^4 \\ -\frac{1}{x^2 y^4} \end{pmatrix} \]

        Finalement, notre théorème nous donne:
        \[J_{\bvec{g}\circ f} = J_{\bvec{g}}\left(f\left(x, y\right)\right) J_f\left(x, y\right) = \begin{pmatrix} 3x^2 y^4 \\ -\frac{1}{x^2 y^4} \end{pmatrix} \begin{pmatrix} y^2 & 2xy \end{pmatrix}  = \begin{pmatrix} 3x^2 y^6 & 6x^3 y^5 \\ -\frac{1}{x^2 y^2} & - \frac{2}{xy^3} \end{pmatrix} \]
        comme attendu.

        De plus, on peut remarquer que, puisque notre transformation $J_{\bvec{g} \circ f}$ représente une composition de $J_{f} : \mathbb{R}_+^2 \mapsto \mathbb{R}_+$ et $J_{\bvec{g}} : \mathbb{R}_+ \mapsto \mathbb{R}_+^2$, elle passe par un ensemble qui restreint son espace image sur une dimension, nous savons que $\rang\left(J_{\bvec{g} \circ f}\right) \leq 1$. Nous pouvons vérifier que le déterminant est nul:
        \[\det J_{\bvec{g} \circ f} = -6xy^3 + 6xy^3 = 0\]
    \end{subparag}

\end{parag}

\begin{parag}{Application: Changement de variable}
    Supposons que nous avons le schéma de fonction suivant:
    \[\mathbb{R}^n \over{\mapsto}{$\bvec{h}$} \mathbb{R}^n \over{\mapsto}{$\bvec{g}$} \mathbb{R}^n\]
    tels que $\bvec{h}$ est un changement de variable et $\bvec{g}$ est sa fonction réciproque, i.e.:
    \[\bvec{g} \circ \bvec{h}\left(x_1, \ldots, x_n\right) = \left(x_1, \ldots, x_n\right)\]

    Nous savons donc que le Jacobien de notre composée est:
    \[J_{\bvec{g} \circ \bvec{h}} = \begin{pmatrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1 \end{pmatrix} = I_{n\times n}\]

    Supposons maintenant aussi que $\bvec{h}$ et $\bvec{g}$ sont dérivables sur leurs domaines. Par le théorème de la fonction composée, nous obtenons:
    \begin{multiequation}
    & J_{\bvec{g}}\left(\bvec{h}\left(\bvec{a}\right)\right) \cdot J_{\bvec{h}}\left(\bvec{a}\right) = I_{n \times n} \\
    \implies & J_{\bvec{g}}\left(\bvec{h}\left(\bvec{a}\right)\right) = \left(J_{\bvec{h}}\left(\bvec{a}\right)\right)^{-1} \text{ et } \det\left(J_{\bvec{g}}\right) \det\left(J_{\bvec{h}}\right) = 1
    \end{multiequation}

    Puisqu'une matrice est bijective si et seulement si elle est inversible, nous en déduisons donc la proposition suivante.

    \begin{subparag}{Proposition}
        Soit $\bvec{g} : \mathbb{R}^n \mapsto \mathbb{R}^n$ une fonction dérivable en $\bvec{a}$. $\bvec{g}$ est bijective dans un voisinage de $\bvec{a}$ si et seulement si $\det\left(J_{\bvec{g}}\left(\bvec{a}\right)\right)\neq 0$.
    \end{subparag}
\end{parag}

\begin{parag}{Exemple: Coordonnées polaires}
    Nous avons les fonctions de changement de variable suivantes:
    \[\bvec{h}\left(x, y\right) = \left(r, \phi\right), \mathspace \bvec{g}\left(r, \phi\right) = \left(x, y\right)\]
    
    Pour plus de simplicité sur la fonction qui nous donne $\phi$, prenons $x > 0$ (si on prend $\mathbb{R}^2 \setminus \left\{0\right\}$, cela fonctionnera de la même manière, mais la notation sera plus lourde):
    \[\bvec{g}\left(r, \phi\right) = \begin{pmatrix} r\cos\left(\phi\right) \\ r\sin\left(\phi\right) \end{pmatrix}, \mathspace \bvec{h}\left(x, y\right) = \begin{pmatrix} \sqrt{x^2 + y^2} \\ \arctan\left(\frac{y}{x}\right) \end{pmatrix} \]
    
    Nous savons que la propriété suivante tient:
    \[\left(\bvec{h} \circ \bvec{g}\right)\left(r, \phi\right) = \left(r, \phi\right) \implies J_{\bvec{h} \circ \bvec{g}} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = J_{\bvec{h} \circ \bvec{g}}\left(x, y\right) \cdot J_{\bvec{g}}\left(r, \phi\right)\]

    La matrice Jacobienne de $\bvec{g}$ se calcule relativement facilement:
    \[J_{\bvec{g}} = \begin{pmatrix} \cos\left(\phi\right) & -r\sin\left(\phi\right) \\ \sin\left(\phi\right) & r\cos\left(\phi\right) \end{pmatrix} \implies \det\left(J_{\bvec{g}}\right) = r\left(\cos^2\left(\phi\right) + \sin^2\left(\phi\right)\right) = r \neq 0\]

    Pour calculer la matrice Jacobienne de $\bvec{h}$, utilisons le fait qu'elle soit l'inverse de celle de $\bvec{f}$:
    \[J_{\bvec{h}}= \left(J_{\bvec{g}}\right)^{-1} = \frac{1}{r} \begin{pmatrix} r\cos\left(\phi\right) & r\sin\left(\phi\right) \\ -\sin\left(\phi\right) & \cos\left(\phi\right) \end{pmatrix} = \begin{pmatrix} \cos\left(\phi\right) & \sin\left(\phi\right) \\ -\frac{\sin\left(\phi\right)}{r} & \frac{\cos\left(\phi\right)}{r} \end{pmatrix} \]

    Or, puisque $\cos\left(\phi\right) = \frac{x}{r} = \frac{x}{\sqrt{x^2 + y^2}}$, et de manière similaire pour $\sin\left(\phi\right)$, nous obtenons:
    \[J_{\bvec{h}}\left(x, y\right) = \begin{pmatrix} \frac{x}{\sqrt{x^2 + y^2}} & \frac{y}{\sqrt{x^2 + y^2}} \\ -\frac{y}{x^2 + y^2} & \frac{x}{x^2 + y^2} \end{pmatrix} = \begin{pmatrix} \frac{\partial h_1}{\partial x} & \frac{\partial h_1}{\partial y} \\ \frac{\partial h_2}{\partial x} & \frac{\partial h_2}{\partial y} \end{pmatrix} \]

    Nous pouvons vérifier cette dernière égalité en utilisant la définition explicite de $\bvec{h}$.
\end{parag}

\subsection{Dérivée d'une intégrale qui dépend d'un paramètre}
\begin{parag}{Théorème}
    Soit $I \subset \mathbb{R}$ un ensemble ouvert, soit $f: \left[a, b\right] \times I \mapsto \mathbb{R}$ telle que $\frac{\partial f}{\partial y}$ est continue sur $\left[a, b\right] \times I$, et soit:
    \[g\left(y\right) = \int_{a}^{b} f\left(x, y\right)dx\]

    Alors, $g\left(y\right)$ est de classe $C^1$ sur $I$, et nous avons:
    \[g'\left(y\right) = \int_{a}^{b} \frac{\partial f}{\partial y}\left(x, y\right)dx, \mathspace \forall y \in I\]

    \begin{subparag}{Preuve}
        Considérons le quotient suivant:
        \begin{multiequality}
        D\left(y\right) =\ & \frac{g\left(y\right) - g\left(y_0\right)}{y - y_0} \\
        =\ & \frac{1}{y - y_0} \int_{a}^{b} \left(f\left(x, y\right) - f\left(x, y_0\right)\right)dx \\
        =\ & \int_{a}^{b} \frac{f\left(x, y\right) - f\left(x, y_0\right)}{y - y_0}dx 
        \end{multiequality}

        Par le théorème des accroissement finis, nous savons qu'il existe un $\widetilde{y}$ entre $y$ et $y_0$ tel que:
        \[\frac{\partial f}{\partial y}\left(x, \widetilde{y}\right) = \frac{f\left(x, y\right) - f\left(x, y_0\right)}{y - y_0}\]

        Ceci nous dit donc que:
        \[D\left(y\right) = \int_{a}^{b} \frac{\partial f}{\partial y}\left(x, \widetilde{y}\right)dx\]
        
        Or, puisque $\widetilde{y}$ est entre $y$ et $y_0$, que $\frac{\partial f}{\partial y}$ est continue, nous savons que, quand $y \to y_0$, $\frac{\partial f}{\partial y}\left(x, \widetilde{y}_0\right) \to \frac{\partial f}{\partial y}\left(x, y_0\right)$ par le théorème des deux gendarmes. Ainsi, cela implique que: 
        \[g'\left(y_0\right) = \lim_{y \to y_0} D\left(y\right) = \int_{a}^{b} \frac{\partial f}{\partial y}\left(x, y_0\right)dx \]
        

        \qed
    \end{subparag}
\end{parag}

\begin{parag}{Exemple}
    Considérons la fonction suivante:
    \[g\left(y\right) = \int_{0}^{\frac{\pi}{2}} \sin\left(xy\right)dx\]

    Nous voulons calculer sa dérivée.

    \begin{subparag}{Théorème}
        Nous savons que, par notre théorème:
        \[g'\left(y\right) = \int_{0}^{\frac{\pi}{2}} \cos\left(xy\right)x dx\]

        Si $y = 0$, alors:
        \[g'\left(y\right) = \int_{0}^{\frac{\pi}{2}} x dx = \frac{1}{2}x^2 \eval_{0}^{\frac{\pi}{2}} = \frac{1}{2}\left(\frac{\pi}{2}\right)^2 = \frac{\pi}{8^2}\]

        Si $y \neq 0$, nous pouvons faire une intégrale par partie:
        \[g'\left(y\right) = \frac{1}{y} \int_{0}^{\frac{\pi}{2}} x d\left(\sin\left(xy\right)\right) = \frac{x}{y}\sin\left(xy\right)\eval_{0}^{\frac{\pi}{2}} - \frac{1}{y} \int_{0}^{\frac{\pi}{2}} \sin\left(xy\right)dx\]

        Ce qui est égal à:
        \[\frac{\pi}{2y}\sin\left(\frac{\pi y}{2}\right) + \frac{1}{y^2}\cos\left(yx\right)\eval_{0}^{\frac{\pi}{2}} = \frac{\pi}{2y} \sin\left(\frac{\pi y}{2}\right) + \frac{1}{y^2}\left(\cos\left(\frac{\pi y}{2}\right) - 1\right)\]

    \end{subparag}

    \begin{subparag}{Directement}
        Calculons notre fonction directement:
        \[g\left(y\right) = \int_{0}^{\frac{\pi}{2}} \sin\left(xy\right)dx \over{=}{$y \neq 0$} -\frac{1}{y}\cos\left(xy\right)\eval_{0}^{\frac{\pi}{2}} = -\frac{1}{y}\cos\left(\frac{\pi y}{2} - 1\right)\]

        Calculons maintenant la dérivée:
        \begin{multiequality}
        g'\left(y\right) =\ & -\frac{1}{y^2} + \frac{1}{y^2}\cos\left(\frac{\pi y}{2}\right) + \frac{1}{y} \sin\left(\frac{\pi y}{2}\right) \cdot \frac{\pi}{2}  \\
        =\ & \frac{\pi}{2y}\sin\left(\frac{\pi y}{2}\right) + \frac{1}{y^2}\left(\cos\left(\frac{\pi y}{2}\right) - 1\right) 
        \end{multiequality}
        comme attendu.

        Notez que, si nous voulons calculer les limites de $g\left(y\right)$ et $g'\left(y\right)$ en 0, nous pouvons utiliser le développement limité de cosinus autour de 0. Ceci nous permettrait de démontrer que cette fonction et sa dérivée sont continues en $y = 0$.
    \end{subparag}
\end{parag}

\begin{parag}{Rappel: Théorème Fondamental du calcul intégral}
    Soit $f$ une fonction continue. Alors, nous avons:
    \[\frac{d}{dt}\left(\int_{a}^{t} f\left(y\right)dy\right) = f\left(t\right), \mathspace \frac{d}{dt}\left(\int_{t}^{b} f\left(y\right)dx\right) = \frac{d}{dt}\left(- \int_{b}^{t} f\left(y\right) dx\right) = -f\left(t\right)\]

    Nous pouvons maintenant combiner nos résultats, et obtenir le théorème suivant.
\end{parag}

\begin{parag}{Théorème}
    Soient $I, J \subset \mathbb{R}$ deux ensembles ouverts, soient $g, h : I \mapsto \mathbb{R}$ des fonctions continûment dérivables, et soit $f : J \times I \mapsto \mathbb{R}$ une fonction telle que $\frac{\partial f}{\partial t}\left(x, t\right)$ est continue sur $I$. Finalement, soit: 
    \[A\left(t\right) = \int_{h\left(t\right)}^{g\left(t\right)} f\left(x, t\right)dx\]
    
    Alors, $A\left(t\right)$ est continûment dérivable sur $I$, et on a: 
    \[A'\left(t\right) = f\left(g\left(t\right), t\right) g'\left(t\right) - f\left(h\left(t\right), t\right)h'\left(t\right) + \int_{h\left(t\right)}^{g\left(t\right)} \frac{\partial f}{\partial t}\left(x, t\right)dx \]
    
    \begin{subparag}{Remarque}
        Ce théorème doit être connu, car il y a souvent un exercise où nous devons l'utiliser en examen.
    \end{subparag}

    \begin{subparag}{Preuve}
        Dans l'idée, nous pouvons définir $F : \mathbb{R}^3 \mapsto \mathbb{R}$ telle que:
        \[F\left(g, h, t\right) = \int_{h}^{g} f\left(x, t\right)dx\]

        De plus, nous pouvons définir $T : \mathbb{R} \mapsto \mathbb{R}^3$:
        \[T\left(t\right) = \left(g\left(t\right), h\left(t\right), t\right)\]

        Ainsi, nous avons:
        \[A\left(t\right) = F\left(g\left(t\right), h\left(t\right), t\right) = F\left(T\left(t\right)\right)\]

        Alors, par le théorème de la dérivée d'une fonction composée, on a:
        \[A'\left(t\right) = J_{F \circ T} = \nabla F\left(g, h, t\right) \begin{pmatrix} g'\left(t\right) \\ h'\left(t\right) \\ 1 \end{pmatrix} = \frac{\partial F}{\partial g}g'\left(t\right) + \frac{\partial F}{\partial h} h'\left(t\right) + \frac{\partial F}{\partial t}\cdot 1\]

        Mais, par le théorème fondamental du calcul intégral, nous obtenons:
        \[A'\left(t\right) = \underbrace{f\left(g\left(t\right), t\right)}_{\frac{\partial F}{\partial g}}g'\left(t\right) - \underbrace{f\left(h\left(t\right), t\right)}_{\frac{\partial F}{\partial h}}h'\left(t\right) + \int_{h\left(t\right)}^{g\left(t\right)} \frac{\partial f}{\partial t}\left(x, t\right)dx\]

        \qed
    \end{subparag}

    \begin{subparag}{Note personnelle: Intuition}
        L'intuition de cette formule est intimement liée avec sa preuve. Ainsi, refaisons là en utilisant des étiquettes différentes sur ce que nous pouvons reconnaître, afin de voir que nous ne partons pas loin des connaissances que nous avons déjà. Pour commencer, il est possible de démontrer que:
        \[\frac{\partial}{\partial x} f\left(g\left(x, y\right), h\left(x, y\right)\right) = \frac{\partial f\left(g, h\right)}{\partial g} \cdot \frac{\partial g\left(x, y\right)}{\partial x} + \frac{\partial f\left(g, h\right)}{\partial h} \cdot \frac{\partial h\left(x, y\right)}{\partial x}\]

        Ceci est une généralisation de la règle de la dérivée en chaine. Définissons maintenant: 
        \[F\left(x, t\right) = \int_a^x f\left(\xi, t\right)d\xi \implies A\left(t\right) = F\left(g\left(t\right), t\right) - F\left(h\left(t\right), t\right)\]
        
        Ainsi, en dérivant, nous obtenons: 
        \[A'\left(t\right) = \frac{\partial F\left(g, t\right)}{\partial g} \cdot \frac{\partial g}{\partial t} + \frac{\partial F\left(g, t\right)}{\partial t} - \frac{\partial F\left(h, t\right)}{\partial h} \cdot \frac{\partial h}{\partial t} - \frac{\partial F\left(h, t\right)}{\partial t}\]
        
        Par un argument similaire à la preuve, il est raisonnable de se convaincre que, en utilisant le théorème fondamental du calcul intégral: 
        \[\frac{\partial F\left(g, t\right)}{\partial g} = f\left(g, t\right), \mathspace -\frac{\partial F\left(h, t\right)}{\partial h} = -f\left(h, t\right)\]
        
        Aussi, comme nous l'avons démontré dans un théorème plus tôt, nous avons: 
        \begin{multiequality}
        \frac{\partial F\left(g, t\right)}{\partial t} - \frac{\partial F\left(h, t\right)}{\partial t} =\ & \frac{\partial}{\partial t}\left(F\left(g,t\right) - F\left(h, t\right)\right) \\
        =\ & \frac{\partial}{\partial t} \int_{h}^{g} f\left(x, t\right) dx \\
        =\ & \int_{h}^{g} \frac{\partial f}{\partial t}\left(x, t\right)dx 
        \end{multiequality}

        En mettant tout ensemble, nous obtenons le résultat que nous cherchions. Notez que ce raisonnement peut se faire très rapidement sur une feuille de brouillon pendant un examen, en faisant toujours attention selon quoi on dérive. Si les notations, comme $\frac{\partial f\left(g, t\right)}{\partial g}$, vous semblent bizarre, n'hésitez pas à les comparer avec les notations suivantes pour la dérivée en chaine classique: 
        \[\frac{df\left(g\left(x\right)\right)}{dx} = \frac{df\left(g\left(x\right)\right)}{dg} \cdot \frac{dg\left(x\right)}{dx} = \frac{df\left(g\right)}{dg} \cdot \frac{dg\left(x\right)}{dx}\]

        Ces notations peuvent prend un peu de temps à assimiler, mais elles sont très pratiques (notamment en physique, par exemple pour l'équation de Lagrange, où on dérive une fonction ``selon des fonctions'' (la position et sa dérivée)! \smiley).
    \end{subparag}
\end{parag}

\begin{parag}{Exemple}

    Calculons la primitive de la fonction suivante:
    \[F\left(t\right) = \int_{2t}^{3t^2} e^{t + x}dx\]

    Nous allons appliquer notre théorème. Nous avons:
    \[h\left(t\right) = 2t, \mathspace g\left(t\right) = 3t^2, \mathspace f\left(x, t\right) = e^{x + t}\]

    Ainsi, par notre théorème:
    \begin{multiequality}
    F'\left(t\right) =\ & e^{3t^2 + t} \underbrace{g'\left(t\right)}_{6t} - e^{2t + t}\underbrace{h'\left(t\right)}_{2} + \int_{2t}^{3t^2} \frac{\partial e^{t + x}}{\partial t} dx \\
    =\ & e^{3t^2 + t}\cdot 6t - e^{3t}\cdot 2 + \int_{2t}^{3t^2} e^{x} e^{t} dx \\
    =\ & 6t e^{3t^2 + t} - 2e^{3t} + e^{t}\left(e^{3t^2} - e^{2t}\right) \\
    =\ & \left(6t + 1\right)e^{3t^2 + t} - 3e^{3t} 
    \end{multiequality}

    \begin{subparag}{Vérification}
        De manière générale, il n'est pas toujours possible de calculer $F\left(t\right)$ explicitement, mais ici c'est possible et donc nous pouvons l'utiliser pour vérifier notre résultat:
        \[F\left(t\right) = \int_{2t}^{3t^2}  e^{t} e^x dx = e^t\left(e^{3t^2} - e^{2t}\right) = e^{3t^2 + t} - 3e^{3t}\]

        Ainsi: 
        \[F'\left(t\right) = \left(6t + 1\right)e^{3t^2 + t} - 3e^{3t}\]
        comme attendu.
    \end{subparag}
\end{parag}

\end{document}
