% !TeX program = lualatex

\documentclass[a4paper]{article}

% Expanded on 2022-05-02 at 10:19:02.

\usepackage{../../style}

\title{Analyse 2}
\author{Joachim Favre}
\date{Lundi 02 mai 2022}

\begin{document}
\maketitle

\lecture{19}{2022-05-02}{Fin des études d'extremums}{
\begin{itemize}[left=0pt]
    \item Explication et preuve d'une proposition qui donne des hypothèses équivalentes pour le théorème de la condition suffisante pour un extremum local quand $n = 2$.
    \item Explication d'un théorème similaire pour $n = 3$.
    \item Explication de la méthode pour trouver les minimums et maximums globaux sur un ensemble compact.
    \item Introduction aux fonctions implicites.
\end{itemize}
}

\begin{parag}{Proposition: Hypothèses équivalentes pour le théorème de la condition suffisante pour un extremum local quand $n = 2$}
    Dans le cas où $n = 2$, nous pouvons réécrire les conditions de notre théorème. 

    Notre matrice Hessienne est donnée par: 
    \[\Hess_f\left(\bvec{a}\right) = \begin{pmatrix} \frac{\partial^{2} f}{\partial x^{2}} & \frac{\partial^2 f}{\partial y \partial x} \\ \frac{\partial^2 f}{\partial x \partial y} & \frac{\partial^{2} f}{\partial y^{2}}  \end{pmatrix} = \begin{pmatrix} r & s \\ s & t \end{pmatrix} \]
    
    Nous avons les équivalences suivantes:
    \begin{enumerate}
        \item $\lambda_1 > 0, \lambda_2 > 0 \iff \det \Hess_f\left(\bvec{a}\right) > 0 \text{ et } r > 0$ 
        \item $\lambda_1 < 0, \lambda_2 < 0 \iff \det \Hess_f\left(\bvec{a}\right) > 0 \text{ et } r < 0$ 
        \item $\lambda_1 > 0, \lambda_2 < 0 \text{ ou } \lambda_1 < 0, \lambda_2 > 0 \iff \det \Hess_f\left(\bvec{a}\right) < 0$ 
    \end{enumerate}

    \demonstrationaconnaitre

    \begin{subparag}{Preuve}
        Pour commencer, nous savons que le déterminant et la trace d'une matrice sont des invariants de conjugaisons. Ainsi, si on a: 
        \[O \begin{pmatrix} r & s \\ s & t \end{pmatrix} O^{-1} = \begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix} \iff \begin{pmatrix} r & s \\ s & t \end{pmatrix} = O^{-1} \begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix} O\]
        
        Alors, on obtient: 
        \[rt - s^2 = \det\Hess_f\left(\bvec{a}\right) = \det\left(O\right)\lambda_1 \lambda_2 \det\left(O^{-1}\right) = \lambda_1 \lambda_2\] 
        \[r + t = \Tr\Hess_f\left(\bvec{a}\right) = \Tr\left(O D O^{-1}\right) = \Tr\left(O^{-1} O D\right) = \Tr\left(D\right) = \lambda_1 + \lambda_2\]
    \end{subparag}

    \begin{subparag}{Preuve point 1 $\implies$}
         Commençons par montrer la direction $\implies$. Ainsi, nous supposons que $\lambda_1 > 0, \lambda_2 > 0$.

         Alors, clairement, $\det\Hess_f\left(\bvec{a}\right) = \lambda_1 \lambda_2 > 0$. Aussi, nous voyons que: 
         \[\lambda_1 \lambda_2 = rt - s^2 > 0 \implies rt > s^2 \geq 0 \implies rt > 0\]
         donc $r$ et $t$ sont de même signe.

         Nous pouvons aussi voir que: 
         \[\Tr\Hess_f\left(\bvec{a}\right) = \underbrace{\lambda_1}_{> 0} + \underbrace{\lambda_2}_{> 0} = r + t > 0\]
         donc $r$ et $t$ doivent être les deux strictement positifs, puisqu'ils ont le même signe.

         Nous en déduisons bien que $\det\Hess_f\left(\bvec{a}\right) > 0$ et $r > 0$.
    \end{subparag}
    
    \begin{subparag}{Preuve point 1 $\impliedby$}
        Supposons que $\det\Hess_f\left(\bvec{a}\right) > 0$ et $r > 0$.

        Alors, puisque $\det\Hess_f\left(\bvec{a}\right) = \lambda_1 \lambda_2 > 0$, nous en déduisons que $\lambda_1$ et $\lambda_2$ sont de même signe. De plus, nous voyons aussi que $rt > s^2 \geq 0 \implies rt > 0$.

        Ainsi, puisque $rt > 0$ et $r > 0$, nous obtenons que $t > 0$. De plus, cela implique que: 
        \[\Tr\Hess_f\left(\bvec{a}\right) = \lambda_1 + \lambda_2 = \underbrace{r}_{> 0} + \underbrace{t}_{> 0} > 0\]
        
        Puisque $\lambda_1$ et $\lambda_2$ sont de mêmes signes, et $\lambda_1 + \lambda_2 > 0$, nous en déduisons bien que $\lambda_1 > 0$ et $\lambda_2 > 0$.
    \end{subparag}

    \begin{subparag}{Preuve point 2 $\implies$}
         Commençons par montrer la direction $\implies$. Ainsi, nous supposons que $\lambda_1 < 0, \lambda_2 < 0$.

         Alors, clairement, $\det\Hess_f\left(\bvec{a}\right) = \lambda_1 \lambda_2 > 0$. Aussi, nous voyons que: 
         \[\lambda_1 \lambda_2 = rt - s^2 > 0 \implies rt > s^2 \geq 0 \implies rt > 0\]
         donc $r$ et $t$ sont de même signe.

         Nous pouvons aussi voir que: 
         \[\Tr\Hess_f\left(\bvec{a}\right) = \underbrace{\lambda_1}_{< 0} + \underbrace{\lambda_2}_{< 0} = r + t < 0\]
         donc $r$ et $t$ doivent être les deux strictement négatifs, puisqu'ils ont le même signe.

         Nous en déduisons bien que $\det\Hess_f\left(\bvec{a}\right) > 0$ et $r < 0$.
    \end{subparag}
    
    \begin{subparag}{Preuve point 2 $\impliedby$}
        Supposons que $\det\Hess_f\left(\bvec{a}\right) > 0$ et $r < 0$.

        Alors, puisque $\det\Hess_f\left(\bvec{a}\right) = \lambda_1 \lambda_2 > 0$, nous en déduisons que $\lambda_1$ et $\lambda_2$ sont de même signe. De plus, nous voyons aussi que $rt > s^2 \geq 0 \implies rt > 0$.

        Ainsi, puisque $rt > 0$ et $r < 0$, nous obtenons que $t < 0$. De plus, cela implique que: 
        \[\Tr\Hess_f\left(\bvec{a}\right) = \lambda_1 + \lambda_2 = \underbrace{r}_{< 0} + \underbrace{t}_{< 0} < 0\]
        
        Puisque $\lambda_1$ et $\lambda_2$ sont de mêmes signes, et $\lambda_1 + \lambda_2 < 0$, nous en déduisons bien que $\lambda_1 < 0$ et $\lambda_2 < 0$.
    \end{subparag}

    \begin{subparag}{Preuve point 3}
        Nous voyons que: 
        \[\det\Hess_f\left(\bvec{a}\right) < 0 \iff \lambda_1 \lambda_2 < 0 \iff \lambda_1 \text{ et } \lambda_2 \text{ sont de signes opposés}\]
        
    \end{subparag}

    \begin{subparag}{Note personnelle}
        La démonstration de ce théorème peut sembler très longue et compliquée, mais elle ne l'est pas! À partir du moment où on sait que le déterminant est donné par $ad - bc$ et que la trace est donnée par la somme des éléments diagonaux, il suffit de poser nos hypothèses et de simplement voir ce que nous pouvons en déduire, en gardant en tête où nous voulons aller.
    \end{subparag}
\end{parag}

\begin{parag}{Résumé du cas $n = 2$}
    Soit $f$ une fonction de classe $C^2$ au voisinage de $\bvec{a} = \left(a_1, a_2\right)$, et soit sa matrice Hessienne: 
    \[\Hess_f\left(\bvec{a}\right) = \begin{pmatrix} r & s \\ s & t \end{pmatrix} \]
    
    \begin{enumerate}[left=0pt]
        \item Si $\det\Hess_f\left(\bvec{a}\right) = rt - s^2 > 0$ et $r > 0$, alors nous avons un minimum local: 
        \[f\left(u, v\right) - f\left(\bvec{a}\right) \approx \underbrace{\frac{1}{2} \lambda_1 \left(u - a_1\right)^2}_{> 0} + \underbrace{\frac{1}{2} \lambda_2 \left(v - a_2\right)^2}_{> 0} > 0\]
        \item Si $\det\Hess_f\left(\bvec{a}\right) = rt - s^2 > 0$ et $r < 0$, alors nous avons un un maximum local: 
        \[f\left(u, v\right) - f\left(\bvec{a}\right) \approx \underbrace{\frac{1}{2} \lambda_1 \left(u - a_1\right)^2}_{< 0} + \underbrace{\frac{1}{2} \lambda_2 \left(v - a_2\right)^2 < 0}_{< 0}\]
    \item Si $\det\Hess_f\left(\bvec{a}\right) = rt - s^2 < 0$, alors il existe $u, v$ dans tout voisinage de $\bvec{a}$ tels que nous n'avons pas d'extremum local: 
        \[f\left(u, v\right) - f\left(\bvec{a}\right) \approx \underbrace{\frac{1}{2} \lambda_1 \left(u - a_1\right)^2}_{> 0} + \underbrace{\frac{1}{2} \lambda_2 \left(v - a_2\right)}_{< 0}\]
    
    \item Si $\det\Hess_f\left(\bvec{a}\right) = 0$, alors nous n'avons pas de conclusion. Par exemple, $f\left(x, y\right) = x^4 + y^4$ a un maximum local en $\bvec{0}$, $f\left(x,y\right) = -x^4 - y^4$ a un minimum local en $\bvec{0}$, et $f\left(x, y\right) = x^4 - y^4$ n'a pas d'extremum local en $\bvec{0}$, alors que le déterminant de toutes leurs matrice Hessiennes est nul en ce point.
    \end{enumerate}
\end{parag}

\begin{parag}{Conditions équivalentes aux conditions suffisantes pour $n = 3$}
    Soit $f$ une fonction de classe $C^2$ au voisinage de $\bvec{a}$, et soit sa matrice Hessienne: 
    \[\Hess_f\left(\bvec{a}\right) = \begin{pmatrix} \frac{\partial^{2} f}{\partial x_1^{2}} & \frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_3 \partial x_1} \\ \frac{\partial^2 f}{\partial x_1 \partial x_2} & \frac{\partial^{2} f}{\partial x_1^{2}} & \frac{\partial^2 f}{\partial x_3 \partial x_2} \\ \frac{\partial^2 f}{\partial x_1 \partial x_3} & \frac{\partial^2 f}{\partial x_2 \partial x_3} & \frac{\partial^{2} f}{\partial x_3^{2}} \end{pmatrix} \]
    
    Nous définissons $\Delta_1$ le déterminant de la matrice $1\times1$ avec le coin en haut à gauche (mineure principale de taille $1 \times 1$), $\Delta_2$ le déterminant de la matrice $2 \times 2$ avec le coin au même endroit (mineure principale de taille $2 \times 2$), et $\Delta_3 = \det\Hess_f\left(\bvec{a}\right)$:
    \imagehere[0.3]{MineuresPrincipalesMatriceHessienne.png}

    Nous avons donc:
    \[\Delta_1 = \frac{\partial^{2} f}{\partial x_1^{2}}, \mathspace \Delta_2 = \frac{\partial^{2} f}{\partial x_1^{2}} \cdot \frac{\partial^{2} f}{\partial x_2^{2}} - \frac{\partial^2 f}{\partial x_2 \partial x_1} \cdot \frac{\partial^2 f}{\partial x_1 \partial x_2}, \mathspace \Delta_3 = \det\Hess_f\]
    
    \begin{enumerate}[left=0pt]
        \item Si $\Delta_1 > 0, \Delta_2 > 0, \Delta_3 > 0$, alors $\bvec{a}$ est un point de minimum local (et $\Hess_f\left(\bvec{a}\right)$ est dite définie positive).
        \item Si $\Delta_1 < 0, \Delta_2 > 0, \Delta_3 < 0$, alors $\bvec{a}$ est un point de maximum local.
        \item Autrement, si $\Delta_3 \neq 0$, alors il n'y a pas d'extremum local en $\bvec{a}$.
        \item Si $\Delta_3 = 0$, alors nous ne pouvons rien conclure.
    \end{enumerate}
    
    \begin{subparag}{Preuve}
        Nous acceptons ce théorème sans preuve.
    \end{subparag}
\end{parag}

\begin{parag}{Exemple}
    Prenons la fonction suivante: 
    \[f\left(x, y\right) = y^3 + 3y^2 - 4xy + x^2\]
    
    Nous pouvons remarquer que $f$ est de classe $C^{\infty}\left(\mathbb{R}^2\right)$, donc ses points critiques sont ses point stationnaires. Nous cherchons de tels points, ainsi calculons le gradient: 
    \[\nabla f\left(x, y\right) = \left(-4y + 2x, 3y^2 + 6y - 4x\right)\]

    En posant $\nabla f\left(x, y\right) = \left(0, 0\right)$ on obtient:
    \[\begin{systemofequations} 4y = 2x \\ 3y^2 + 6y - 4x = 0 \end{systemofequations} \iff \begin{systemofequations} x = 2y \\y\left(3y - 2\right) = 0 \end{systemofequations}\]

    Et donc, nous avons deux solutions. Soit $y = 0$, ce qui implique $x = 0$, soit $y = \frac{2}{3}$, ce qui implique $x = \frac{4}{3}$. Nous avons donc deux points stationnaires: $\left(0, 0\right)$ et $\left(\frac{4}{3}, \frac{2}{3}\right)$. 

    Regardons le premier point: 
    \[\Hess_f\left(0, 0\right) = \begin{pmatrix} 2 & -4 \\ -4 & 6 \end{pmatrix} \implies \det\Hess_f\left(0, 0\right) = 12 - 16 = -4 < 0\]

    Nous pouvons en déduire qu'il n'y a pas d'extremum local en $\left(0, 0\right)$. Regardons maintenant le deuxième point: 
    \[\Hess_f\left(\frac{4}{3}, \frac{2}{3}\right) = \begin{pmatrix} 2 & -4 \\ -4 & 10 \end{pmatrix} \implies \det\Hess_f\left(\frac{4}{3}, \frac{2}{3}\right) = 20 - 16 = 4 > 0\]
    
    Or, puisque $r = 2 > 0$, nous avons un minimum local en $\left(\frac{4}{3}, \frac{2}{3}\right)$.
\end{parag}

\subsection[Min et max sur un compact]{Minimum et maximum d'une fonction continue sur un compact}

\begin{parag}{Rappel: Théorème}
    Une fonction continue sur un sous-ensemble compact $D \subset \mathbb{R}^n$ atteint son minimum et son maximum. En d'autres mots, $\exists \bvec{c}_1, \bvec{c}_2$ tels que: 
    \[f\left(\bvec{c}_1\right) = \min_{\bvec{x} \in D} f\left(\bvec{x}\right), \mathspace f\left(\bvec{c}_2\right) = \max_{\bvec{x} \in D} f\left(\bvec{x}\right)\]
\end{parag}

\begin{parag}{Méthode}
    Nous voulons une méthode pour trouver ces $\bvec{c}_1, \bvec{c}_2$. Pour faire cela, il faut:
    \begin{enumerate}
        \item Trouver les points critiques $\left\{\bvec{c}_i\right\}$ de $f$ sur $\mathring{D}$ (l'intérieur de $D$). Calculer les valeurs $f\left(\bvec{c}_i\right)$.
        \item Trouver les points $\left\{\bvec{d}_j\right\}$ de minimum et maximum de $f\left(\partial D\right)$ ($\partial D$ est la frontière de $D$). Calculer les valeurs $f\left(\bvec{d}_j\right)$.
        \item Choisir le minimum et le maximum parmi les valeurs qu'on a trouvées.
    \end{enumerate}

    Notez que le deuxième point peut être très dur à calculer. La frontière peut par exemple être donnée par morceaux, auquel cas il ne faut pas oublier les coins. Ensuite, nous évaluons $f$ sur la frontière à l'aide de cette dépendance entre $x$ et $y$.
\end{parag}

\begin{parag}{Exemple}
    Soit la fonction $f\left(x, y\right) = x^2 + 2y^2 - 2y + 3$. Nous voulons trouver son minium et maximum absolus sur le disque fermé suivant:  
    \[D = \left\{x^2 + y^2 \leq 4\right\}\]
    
    \begin{subparag}{Points critiques}
        Notre fonction est de classe $C^{\infty}\left(\mathring{D}\right)$, donc les points critiques sont les points stationnaires. 

        Le gradient de notre fonction est donné par $\nabla f\left(x, y\right) = \left(2x, 4y - 2\right)$, ainsi en posant $\nabla f\left(x, y\right) = \left(0, 0\right)$, nous trouvons: 
        \[x = 0, \mathspace y = \frac{1}{2}\]
        
        Ainsi, $\left(0, \frac{1}{2}\right) \in \mathring{D}$ est le seul point critique. Notez que nous n'avons pas besoin de faire d'analyse supplémentaire pour savoir si c'est réellement un extremum ou non, puisque nous allons comparer la valeurs avec celles de la frontière de toutes façons.
    \end{subparag}

    \begin{subparag}{Frontière}
        Notre frontière est donnée par $\partial D = \left\{x^2 + y^2 = 4\right\}$, donc nous avons la contrainte suivante: 
        \[x^2 = 4 - y^2\]

        Donc, la fonction sur notre frontière est donnée par: 
        \[\widetilde{f}\left(y\right) = \underbrace{4 - y^2}_{= x^2} + 2y^2 - 2y + 3 = y^2 - 2y + 7, \mathspace \text{sur } \left[-2, 2\right]\]
        
        Cette une fonction d'une seule variable, donc nous pouvons la dériver et faire notre analyse habituelle (qui semble si triviale maintenant): 
        \[\widetilde{f}'\left(y\right) = 2y - 2 = 0 \implies y = 1 \implies x = \pm \sqrt{3}\]
        
        Nous avons donc deux points candidats: $\left(\pm \sqrt{3}, 1\right)$. Aussi, nous ne devons pas oublier les points au bord, avec $y = 2$ et $y = -2$.
    \end{subparag}

    \begin{subparag}{Comparaison}
        Calculons la valeur de nos fonctions à nos différents points:  
        \[f\left(0, \frac{1}{2}\right) = \frac{5}{2}\]
        \[f\left(\pm \sqrt{3}, 1\right) = \widetilde{f}\left(1\right) = 1 - 2 + 7 = 6\] 
        \[\widetilde{f}\left(-2\right) = 4 + 4 + 7 = 15 = f\left(0, -2\right)\] 
        \[\widetilde{f}\left(2\right) = 4 - 4 + 7 = 7 = f\left(0, 2\right)\]
        
        Nous trouvons donc finalement que le minimum global (absolu) de $f$ sur $D$ est en $\left(0, \frac{1}{2}\right)$, et que son maximum global (absolu) sur $D$ est en $\left(0, -2\right)$.
        
        \imagehere[0.6]{ExempleMinMaxAbsolus.png}
    \end{subparag}
\end{parag}

\subsection{Théorème des fonctions implicites}
\begin{parag}{Définition: Fonction implicite}
    Une \important{fonction implicite} est une dépendance $f = f\left(\bvec{x}\right)$ qui est définie par une équation.
\end{parag}

\begin{parag}{Exemple 1}
    Prenons $F\left(x, y\right) = 2x + 3y$. Alors, $F\left(x, y\right) = 0$ définit une fonction implicite $y = f\left(x\right)$ pour tout $x \in \mathbb{R}$. En effet, cela nous donne: 
    \[2x + 3f\left(x\right) = 0 \iff f\left(x\right) = -\frac{2}{3} x, \mathspace \forall x \in \mathbb{R}\]
    
    Nous aurions aussi pu considérer $x = g\left(y\right)$: 
    \[2g\left(y\right) + 3y = 0 \iff g\left(y\right) = -\frac{3}{2}y, \mathspace \forall y \in \mathbb{R}\]
    
    Nous obtenons la même fonction, décrite différemment. 
\end{parag}

\begin{parag}{Exemple 2}
    Prenons $F\left(x, y\right) = x^2 + y^2 - 1$. Nous nous demandons si $F\left(x, y\right) = 0$ nous définit une fonction. 

    Soit $\left(a, b\right)$ un point sur le cercle de rayon 1, donc tels que $a^2 + b^2 = 1$. Si $b > 0$, alors nous trouvons $y = \sqrt{1 - x^2}$ au voisinage de $\left(a, b\right)$. Si $b < 0$, alors nous trouvons $y = -\sqrt{1 - x^2}$ au voisinage de $\left(a, b\right)$.

    Cependant, si $b = 0$, nous avons deux solutions pour chaque $x$ dans tout voisinage de $b$. Par exemple, en considérant un voisinage de $\left(-1, 0\right)$, nous pouvons voir que tout $y$ aurait besoin de deux valeurs pour un $x$:
    \svghere[0.5]{FonctionImpliciteCerclePOintsProblemes.svg}

     Donc, puisqu'il faudrait avoir deux valeurs pour un $x$, nous ne pouvons pas avoir une fonction $y = f\left(x\right)$ au voisinage de $b = 0$.
\end{parag}

\end{document}
